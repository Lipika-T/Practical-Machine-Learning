---
title: "Machine Learning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

This data used for this project is related to physical activity using measurements from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. A suitable model was built using the training dataset to predict the manner in which the exercise was done (represented by the ```classe``` variable in the dataset).

### Getting and cleaning data

The training and testing data sets were downloaded from the URLs.
```{r}
train_data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test_data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
dim(train_data)
dim(test_data)
```
The dataset was processed to select the predictors to be used in the model.

The non-numeric variables (columns 1-8) giving information such as that of the subject and time of activity were removed from the set.

```{r}
train_data <- train_data[,-c(1:8)]
test_data <- test_data[,-c(1:8)]
```
Next, the variables with near zero variance were identified and removed.
```{r}
library(caret)
nz<-nearZeroVar(train_data)
train_data<-train_data[,-nz]
test_data<-test_data[,-nz]
```
Several variables were found to have a high proportion of missing (NA) values. The variables with more than 90% missing values were removed. 
```{r}
na_col <- sapply(train_data, function(x) mean(is.na(x))>0.9)
train_fin <- train_data[,na_col==FALSE]
test_fin<-test_data[,na_col==FALSE]
```
The training set was split into a training set for building the model and a validation set to test the accuracy of the models.
```{r}
set.seed(1223)
inTrain <- createDataPartition(train_fin$classe,p=0.6,list=FALSE)
training <- train_fin[inTrain,]
val <- train_fin[-inTrain,]
```
## Building the prediction model

1. Decision tree (CART)
```{r}
library(rattle)
fit_dt <- train(classe~.,data=training,method="rpart")
fancyRpartPlot(fit_dt$finalModel)
```

The accuracy was tested on the validation set to assess the out-of-sample error.
```{r}
tab_dt <- confusionMatrix(predict(fit_dt,val),val$classe)
tab_dt
plot(tab_dt$table,col=tab_dt$byClass,main=paste("Decision Tree - Accuracy =",round(tab_dt$overall['Accuracy'],4)))
```

The accuracy of the model was about ```r round(tab_dt$overall['Accuracy'],4)*100```% which is quite low. Other models were tried to increase the accuracy.


2. Random Forest

```{r}
fit_rf <- train(classe~.,data=training,method="rf",ntree=100)
tab_rf <- confusionMatrix(predict(fit_rf,val),val$classe)
tab_rf
plot(tab_rf$table,col=tab_rf$byClass,main=paste("Random forest - Accuracy =",round(tab_rf$overall['Accuracy'],4)))
```

The accuracy of the model was about ```r round(tab_rf$overall['Accuracy'],4)*100```%.  Since this accuracy was high, the random forest model was selected.


### Final prediction - predicting classe for test data set

```{r}
predict(fit_rf,test_fin)
```